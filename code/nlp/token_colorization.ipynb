{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d2f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdcbfb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# this program is a test of tiktoken, and its ability to separate paragraphs into colored tokens\n",
    "# based on a selected LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c4cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31ff312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c47f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6e2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c56e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fb9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a099bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = f.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3bb362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb77bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = f.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e35a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = f.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, syle=color)\n",
    "    # should print in color\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7bd74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acf5c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, syle=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "705cf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ec8bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, style=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1f1e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccbfda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%notebook token_colorization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92d24709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # replace space with a middle dot\n",
    "        token = token.replace(\" \", \".\")\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, style=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b280c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f518298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # replace space with a middle dot\n",
    "        token = token.replace(\" \", \"·\")\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, style=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9bc14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b53b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%notebook token_colorization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5554ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d64a888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # replace space with a middle dot\n",
    "        token = token.replace(\" \", \"·\")\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, style=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    # log number of tokens\n",
    "    print(f\"num tokens: {len(tokens)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfbf7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
