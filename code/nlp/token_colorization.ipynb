{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a381ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d3110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# this program is a test of tiktoken, and its ability to separate paragraphs into colored tokens\n",
    "# based on a selected LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9face1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7559eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad90bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be78bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e39191",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7c45cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ec12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = f.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252d7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aadab124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = f.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e970cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = f.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, syle=color)\n",
    "    # should print in color\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b7e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22417dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, syle=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83cdfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0026016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, style=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2adb0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb6ac6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%notebook token_colorization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58a848dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # replace space with a middle dot\n",
    "        token = token.replace(\" \", \".\")\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, style=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ebe136",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34b96e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_print(filename):\n",
    "    with open(\"hamlet.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_strings = [tokenizer.decode([t]) for t in tokens]\n",
    "    text_obj = Text()\n",
    "    colors = [\"cyan\", \"magenta\", \"yellow\", \"green\", \"red\" \"blue\"]\n",
    "    for i, token in enumerate(token_strings):\n",
    "        # replace space with a middle dot\n",
    "        token = token.replace(\" \", \"Â·\")\n",
    "        # simply cylce through the colors\n",
    "        color = colors[i % len(colors)]\n",
    "        text_obj.append(token, style=color)\n",
    "    # should print in color\n",
    "    console.print(text_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4c0e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_print(\"hamlet.txt\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
